{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3802293e",
   "metadata": {},
   "source": [
    "# Gymnasium CarRacing-v2 with PPO (Vision-based RL)\n",
    "\n",
    "In this notebook, we train a **vision-based** reinforcement learning agent on the `CarRacing-v2` environment using **Proximal Policy Optimization (PPO)** from Stable-Baselines3.\n",
    "\n",
    "Goals:\n",
    "\n",
    "- Use image observations (96Ã—96Ã—3 RGB or preprocessed variants).\n",
    "- Train PPO with a **shared training schedule** consistent with the team (e.g., 0 â†’ 300k â†’ 600k â†’ 1M steps).\n",
    "- Log the **reward per episode** and visualize training curves.\n",
    "- Evaluate **mean reward and variance** at different training stages (checkpoints).\n",
    "- For each checkpoint, record a **demo video** of the agent driving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2557144a",
   "metadata": {},
   "source": [
    "# Import the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4792174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't installed the dependencies, run this once:\n",
    "\n",
    "# !pip install \"gymnasium[box2d]\"\n",
    "# !pip install stable-baselines3[extra]\n",
    "# !pip install pygame\n",
    "# !pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773c1f0",
   "metadata": {},
   "source": [
    "# Import the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cef4147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"Imports successful.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed188e",
   "metadata": {},
   "source": [
    "# Device Detection (GPU / MPS / CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ac9f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon MPS\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff9213",
   "metadata": {},
   "source": [
    "# ðŸŽï¸ Car Racing v2 Environment\n",
    "- Documentation https://gymnasium.farama.org/environments/box2d/car_racing/#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a873baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"Imports successful.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3be17",
   "metadata": {},
   "source": [
    "## Model: PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ea2f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/xtcmir/Downloads/Gym-CarRacing-RL-main 2\n",
      "LOG_DIR: /Users/xtcmir/Downloads/Gym-CarRacing-RL-main 2/logs_PPO\n",
      "MODEL_DIR: /Users/xtcmir/Downloads/Gym-CarRacing-RL-main 2/models_PPO\n",
      "VIDEO_DIR: /Users/xtcmir/Downloads/Gym-CarRacing-RL-main 2/videos_PPO\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ALGO_NAME = \"PPO\"\n",
    "\n",
    "# Go from PPO/ up one level to the project root\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "LOG_DIR   = os.path.join(PROJECT_ROOT, f\"logs_{ALGO_NAME}\")\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, f\"models_{ALGO_NAME}\")\n",
    "VIDEO_DIR = os.path.join(PROJECT_ROOT, f\"videos_{ALGO_NAME}\")\n",
    "\n",
    "# Create the folders only if they don't already exist\n",
    "for d in [LOG_DIR, MODEL_DIR, VIDEO_DIR]:\n",
    "    if not os.path.isdir(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"LOG_DIR:\", LOG_DIR)\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n",
    "print(\"VIDEO_DIR:\", VIDEO_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74df9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "carracing_hparams = {\n",
    "    \"total_timesteps\": 1_000_000,\n",
    "    \"checkpoint_steps\": [100_000, 300_000, 600_000, 1_000_000],\n",
    "\n",
    "    # PPO hyperparameters\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"gamma\": 0.99,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"vf_coef\": 0.5,\n",
    "\n",
    "    # env\n",
    "    \"env_id\": \"CarRacing-v3\",\n",
    "\n",
    "    # live plot\n",
    "    \"plot_every\": 1,\n",
    "    \"moving_avg_window\": 5,\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c8cb2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train env created.\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n",
      "Action space: Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def make_train_env():\n",
    "    def _make():\n",
    "        env = gym.make(carracing_hparams[\"env_id\"], render_mode=None)\n",
    "\n",
    "        # Just log with Monitor (no resize/grayscale/framestack for now)\n",
    "        env = Monitor(env, filename=os.path.join(LOG_DIR, \"monitor.csv\"))\n",
    "        return env\n",
    "\n",
    "    return DummyVecEnv([_make])\n",
    "\n",
    "\n",
    "def make_eval_env(render_mode=None):\n",
    "    def _make():\n",
    "        env = gym.make(carracing_hparams[\"env_id\"], render_mode=render_mode)\n",
    "\n",
    "        env = Monitor(env)  # no filename so we don't overwrite training log\n",
    "        return env\n",
    "\n",
    "    return DummyVecEnv([_make])\n",
    "\n",
    "\n",
    "train_env = make_train_env()\n",
    "print(\"Train env created.\")\n",
    "print(\"Observation space:\", train_env.observation_space)\n",
    "print(\"Action space:\", train_env.action_space)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee8e92d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "PPO model created.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    train_env,\n",
    "    n_steps=carracing_hparams[\"n_steps\"],\n",
    "    batch_size=carracing_hparams[\"batch_size\"],\n",
    "    learning_rate=carracing_hparams[\"learning_rate\"],\n",
    "    gamma=carracing_hparams[\"gamma\"],\n",
    "    gae_lambda=carracing_hparams[\"gae_lambda\"],\n",
    "    clip_range=carracing_hparams[\"clip_range\"],\n",
    "    ent_coef=carracing_hparams[\"ent_coef\"],\n",
    "    vf_coef=carracing_hparams[\"vf_coef\"],\n",
    "    verbose=1,\n",
    "    tensorboard_log=LOG_DIR,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(\"PPO model created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccd168",
   "metadata": {},
   "source": [
    "# Training: save checkpoints at multiple stages\n",
    "\n",
    "We train the SAC agent for a total of **1M timesteps**, and save checkpoints at:\n",
    "\n",
    "- 100k steps  \n",
    "- 300k steps  \n",
    "- 600k steps  \n",
    "- 1,000k steps  \n",
    "\n",
    "During training, we do **not spam print rewards**.  \n",
    "Instead, we rely on the `Monitor` log and later **plot the episode rewards**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dc51826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointCallback(BaseCallback):\n",
    "    def __init__(self, save_freqs, model_dir, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.save_freqs = save_freqs\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.num_timesteps in self.save_freqs:\n",
    "            save_path = os.path.join(self.model_dir, f\"ppo_{self.num_timesteps}_steps.zip\")\n",
    "            self.model.save(save_path)\n",
    "            if self.verbose:\n",
    "                print(f\"ðŸ“¦ Saved checkpoint: {save_path}\")\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca59fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5d07739",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freqs=carracing_hparams[\"checkpoint_steps\"],\n",
    "    model_dir=MODEL_DIR,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbe652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /Users/xtcmir/Downloads/Gym-CarRacing-RL-main 2/logs_PPO/PPO_2\n"
     ]
    }
   ],
   "source": [
    "model.learn(\n",
    "    total_timesteps=carracing_hparams[\"total_timesteps\"],\n",
    "    callback=checkpoint_callback,\n",
    "    progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158f019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
